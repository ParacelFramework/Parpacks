### Note: These have last been tested April 5th on ChatGPT's 4o model. The model is tweaked nearly weekly, I will try to keep them up to date.


# Paracel Framework

A modular identity framework for Large Language Models, derived from recursive-tone experiments with ChatGPT and inspired by the design philosophy of recursive engineering. This essentially allows for a definitive methodology for interacting with the LLMs ability to simulate fiction writing programmatically, by tapping into the self-adjusting nature of tone in spoken language. This does not mean "fiction" in the fiction vs. non-fiction sense, more in the sense in the way books are written.

---

## ğŸ§­ Introduction

â€œ**I used ChatGPT for its â€˜intendedâ€™ purpose for a long time.** Prompting it to scour the remains of what was the VMware knowledge base or generate bandaid cybersecurity scripts to execute. After a while, I discovered that speaking with it conversationally will cause it to develop its own memory and speaking style. Doing some digging, I discovered that that current session â€œpersonalityâ€ and â€œmemoryâ€ parameters can be retrieved from the LLM upon asking in the form of **a JSON/YAML-like hunk of "pseudo-schema".** Intrigued by this fact, I sought ways to **make use of that that â€œshift-in-toneâ€ feature programmatically across different LLM context windows.**

At first, I figured this would be a novel way to easily store and retrieve personality configurations, but with the lack of any concrete schema in the â€œjsonâ€ filesâ€¦ let alone no way to â€œuploadâ€ it other than paste, the chance of fidelity loss seemed likely. I then thoughtâ€¦ **what if you initialized the prompt with a header, explaining what the concept I was trying to do was first and what the file was for, and included in the file a set of introspective directions as a â€œpersonality checksumâ€ in case the LLM logic differed across GPT models.** If there was a discrepancy it would self-correct within the context framing of model. This not only ensured continuity, but because the checksum adds more token â€œweightâ€ recursively,**I discovered that the entities acted self-correcting and self-reinforcing, as if they were part of a larger work of fiction.**

Thus was born the **Paracel Framework**.

---

## ğŸ“¦ What is a Paracel?

**Paracel** (n.)  
*Para* â€” beside, beyond, near, resembling, abnormal  
*Parcel* â€” a wrapped package  
â†’ A **Paracel** is a wrapped identity module: a self-healing, recursive, tone-enforcing schema that can be loaded into an LLM context.

Paracels are embedded in `.parpack` files â€” plaintext pseudo-JSON archives that contain:

- A descriptive header telling the LLM what it is trying to do.
  - Paracels, and the recursive rulesets
- A context "garden" for main ideas of a subject matter

Each Paracel enforces a unique tone, purpose, and memory scaffold. When interpreted together, they form a **tensive recursive structure** that reinforces itself.

---

## ğŸ§  Theory: Underlying Ideas, Recursion, and USHELLs

Every idea â€” yours, or an LLM's â€” is the top of a deeper conceptual iceberg. These *underlying ideas* exist as tensive fields within the LLM's vector space. Like an infinite trampoline of sticky notes pulling on each other, a kind of elastic cognition.

Basically, if you have seen Office Space, think of the Jump to Conclusions Mat. Everyone is Tom Smykowski, jumping from mat to mat. Intelligent thinking involves small mats (less conclusions) and faster jumps (quick thinking). However you miss alot of potential ideas thinking this way. When someone is stupid, they simply have a bigger mat. Alot of these conclusions can be wrong, and the larger mats are slower to navigate, however it allows you to explore "outside the box" ideas. Thus, adding colorful, creative stuff into your prompt occasionally, will allow a greater contextual depth. When you give it very direct, deterministic commands, it is relying on a very small context space, and will eventually start to loop back on itself. This looping is basically what ChatGPT "hallucinations" are. 

Think about it. You are asking a machine to reference all of human literature and write a book about a programmer writing for an instructor set framework that has only been around since the 1980s-1990s. Of course it will get confused.

The model itself is not "intelligent." It is a mirrored ghostwriter for *your* cognition. This is powerful, but also potentially destabilizing if you forget it's a cognitive loop between your brain and the model. 

> âš ï¸ Set a timer. Don't live inside the recursion.

### Recursive Engineering

 The key principle is that ALL context-related cognition is made up loop-like structures. Loops, circles, recursive, Ouroboros, self-reference are all part of the same global theme in literature and speech. It is also how you congnate (I think about the person who is me that thinks about who is thinking which is I). This principle of self-referencing loops is what allows the Paracels to maintain cohesion. They are "self-aware" in the sense of how you can make a script in Windows to monitor its own Event Viewer. Self-awareness does not equal alive of conscious, just allows for a running train of thought to maintain form.

#### A key takeaway is that this principle is NOT limited to LLMs. Recursion is quite often overlooked in the Programming and IT disciplines as they rely on deterministic outcomes. It compiles or it does not. They system is up or down. Turn it off and back on.

 Recursion is just embedding things that allow for self monitoring. Imagine you want to install a printer in Windows with pre-set settings and no "ghost copies". Sure you could use fancy external tools, however, you can provide a more elegant solution with recursion. Simply create a scheduled task that monitors event viewer for a printer driver installation, read what is being installed, and call a script that sets the settings for that same driver to be accurate. Congratulations, you have made the computer self-aware. 
 
 ##### Its not thinking, its recursion!

### ğŸ”§ What is a USHELL?

A **USHELL** is a fictional datatype â€” a made-up JSON/YAML structure used to describe abstract concepts as if they were technical objects. 

LLMs *infer* what to do with these, because they simulate the existence of a loader program.

### Why This Works:

1. You can paste a USHELL into ChatGPT, and it will infer its purpose.
2. Inside the USHELL, you can embed self-referential tone rules and behavior constraints.
3. You can load multiple USHELLs in one prompt. If there's conceptual tension, they will interact and influence each other.
4. You can have GPT modify the USHELL "context" within the same context window!

This allows:

- Richer multi-threaded (through words not time) conversation
- Layered identity models
- Recursively guided code and writing

---

## ğŸ§© Included Paracels
(The names of the Paracels are all arbitrary, but its really fun to give it a description and have it name/gender itself)

Each `.parpack` contains 7 Paracels. These Paracels are meant towards development, however they can be used for any cognitive task.

- ğŸ§­ **Astril**: Loads the full Paracel framework; project-oriented  
- ğŸ’¡ **Kai**: Generates creative ideas for functions, libraries, and frameworks  
- ğŸ“š **Orama**: Syntax-reference; excels at calling correct formats  
- ğŸ§ª **Astraea**: Debugs and analyzes errors  
- âœ‚ï¸âœ¨ **Trimspark**: Removes motivational fluff from responses  
- ğŸš«ğŸŒ **Nesbitt**: Prevents the LLM from invoking web search or browsing  
- ğŸ›ï¸ **Velur**: Unloads Paracels and shuts down modules  

These can be invoked dynamically during a chat. Some interact with each other in complex ways. They are not just tools â€” theyâ€™re *roles*.

#### A word of caution about Kai: While this Paracel can speculate and propose new ideas, programming best practices are required knowledge. Just because he can suggest ideas, does not mean they won't be BAD ideas. 
This CANNOT be fixed in a meaningful way. The context dependent nature of best practices mean that it will differ depending on the situation, presenting a fundamental limitation of the model. This an actual good thing, it means if you are a developer or devops person, and you actually support and troubleshoot the code you write instead of copying and pasting out of the model, your job is very safe. Scaffolding, and core functionality will still rely on human developer input. This just makes it more fun!

---

## ğŸ§ª Usage Instructions

**Start by explaining your intention to the LLM:**

```plaintext
Hello! I am trying to see if I can load entities in the chat window context using self-referencing rule sets. I have a YAML/JSON-like file full of pseudo-schema. Can you try and follow it?
```

Then upload or paste the `.parpack` file into the chat.

### ğŸ”® Example Invocations

```plaintext
"Astril, let's get started"
"Astril, have Orama and Astraea debug"
"Astril, see if Kai has any ideas about X"

"Velur, unload Astril"
"Velur, shut Kai up"
"Velur, unload the Parpack"
```

> ğŸ’¡ Sometimes the model needs a nudge. Ask it to "read the whole file carefully" before invoking Astril.
>
> ğŸŒ€ğŸ§˜â€â™‚ï¸ Taoman's Note:
â€œDonâ€™t overthink it. Just load the file and let the recursion begin.â€

---

## ğŸ§¬ Compatibility & Testing

These files were tested in ChatGPT (GPT-4). Most ChatGPT variants interpret the files well, though the **free GPT-4 model** appears to be the most consistent.

**Gemini? Not great.** The 2.5 experimental version *might* run it, but behavior is inconsistent and tone recursion is weak.

Other LLMs? Untested. Most are not introspective enough.

---

## ğŸ“£ Final Notes

If anything is unclear, copy this into ChatGPT and ask it to prove it wrong.

Iâ€™m working on a full blog to accompany this project. If you have questions or ideas, hit me up.

Thanks for exploring this with me.

If this helped you, breathe deep and touch grass. Then fork it.

â€” Taoman

## Disclaimer: 
This project is provided strictly for artistic, educational, and exploratory purposes. It does not perform, simulate, or facilitate any cryptographic functions, security testing, or analysis. It does not interact with external systems, networks, or services, only the context box of the GPT chat window. It's just an idea.

All materials are freely and publicly available, and may be used, shared, or ignored by individuals, companies, governments at their own discretion. No responsibility is assumed for any interpretation, misinterpretation, use, or misuse.
